{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorrt as trt\n",
    "import numpy as np\n",
    "from cuda import cuda, cudart\n",
    "from tensorrt import BuilderFlag\n",
    "from typing import Optional, List\n",
    "import ctypes\n",
    "\n",
    "class HostDeviceMem:\n",
    "    \"\"\"Pair of host and device memory, where the host memory is wrapped in a numpy array\"\"\"\n",
    "    def __init__(self, size: int, dtype: np.dtype):\n",
    "        nbytes = size * dtype.itemsize\n",
    "        host_mem = cuda_call(cudart.cudaMallocHost(nbytes))\n",
    "        pointer_type = ctypes.POINTER(np.ctypeslib.as_ctypes_type(dtype))\n",
    "\n",
    "        self._host = np.ctypeslib.as_array(ctypes.cast(host_mem, pointer_type), (size,))\n",
    "        self._device = cuda_call(cudart.cudaMalloc(nbytes))\n",
    "        self._nbytes = nbytes\n",
    "\n",
    "    @property\n",
    "    def host(self) -> np.ndarray:\n",
    "        return self._host\n",
    "\n",
    "    @host.setter\n",
    "    def host(self, arr: np.ndarray):\n",
    "        if arr.size > self.host.size:\n",
    "            raise ValueError(\n",
    "                f\"Tried to fit an array of size {arr.size} into host memory of size {self.host.size}\"\n",
    "            )\n",
    "        np.copyto(self.host[:arr.size], arr.flat, casting='safe')\n",
    "\n",
    "    @property\n",
    "    def device(self) -> int:\n",
    "        return self._device\n",
    "\n",
    "    @property\n",
    "    def nbytes(self) -> int:\n",
    "        return self._nbytes\n",
    "\n",
    "    def __str__(self):\n",
    "        return f\"Host:\\n{self.host}\\nDevice:\\n{self.device}\\nSize:\\n{self.nbytes}\\n\"\n",
    "\n",
    "    def __repr__(self):\n",
    "        return self.__str__()\n",
    "\n",
    "    def free(self):\n",
    "        cuda_call(cudart.cudaFree(self.device))\n",
    "        cuda_call(cudart.cudaFreeHost(self.host.ctypes.data))\n",
    "        \n",
    "        \n",
    "def check_cuda_err(err):\n",
    "    if isinstance(err, cuda.CUresult):\n",
    "        if err != cuda.CUresult.CUDA_SUCCESS:\n",
    "            raise RuntimeError(\"Cuda Error: {}\".format(err))\n",
    "    if isinstance(err, cudart.cudaError_t):\n",
    "        if err != cudart.cudaError_t.cudaSuccess:\n",
    "            raise RuntimeError(\"Cuda Runtime Error: {}\".format(err))\n",
    "    else:\n",
    "        raise RuntimeError(\"Unknown error type: {}\".format(err))\n",
    "\n",
    "def cuda_call(call):\n",
    "    err, res = call[0], call[1:]\n",
    "    check_cuda_err(err)\n",
    "    if len(res) == 1:\n",
    "        res = res[0]\n",
    "    return res\n",
    "\n",
    "# Allocates all buffers required for an engine, i.e. host/device inputs/outputs.\n",
    "# If engine uses dynamic shapes, specify a profile to find the maximum input & output size.\n",
    "def allocate_buffers(engine: trt.ICudaEngine, profile_idx: Optional[int] = None):\n",
    "    inputs = []\n",
    "    outputs = []\n",
    "    bindings = []\n",
    "    stream = cuda_call(cudart.cudaStreamCreate())\n",
    "    tensor_names = [engine.get_tensor_name(i) for i in range(engine.num_io_tensors)]\n",
    "    for binding in tensor_names:\n",
    "        # get_tensor_profile_shape returns (min_shape, optimal_shape, max_shape)\n",
    "        # Pick out the max shape to allocate enough memory for the binding.\n",
    "        shape = engine.get_tensor_shape(binding) if profile_idx is None else engine.get_tensor_profile_shape(binding, profile_idx)[-1]\n",
    "        shape_valid = np.all([s >= 0 for s in shape])\n",
    "        if not shape_valid and profile_idx is None:\n",
    "            raise ValueError(f\"Binding {binding} has dynamic shape, \" +\\\n",
    "                \"but no profile was specified.\")\n",
    "        size = trt.volume(shape)\n",
    "        if engine.has_implicit_batch_dimension:\n",
    "            size *= engine.max_batch_size\n",
    "        dtype = np.dtype(trt.nptype(engine.get_tensor_dtype(binding)))\n",
    "\n",
    "        # Allocate host and device buffers\n",
    "        bindingMemory = HostDeviceMem(size, dtype)\n",
    "\n",
    "        # Append the device buffer to device bindings.\n",
    "        bindings.append(int(bindingMemory.device))\n",
    "\n",
    "        # Append to the appropriate list.\n",
    "        if engine.get_tensor_mode(binding) == trt.TensorIOMode.INPUT:\n",
    "            inputs.append(bindingMemory)\n",
    "        else:\n",
    "            outputs.append(bindingMemory)\n",
    "    return inputs, outputs, bindings, stream\n",
    "\n",
    "def free_buffers(inputs: List[HostDeviceMem], outputs: List[HostDeviceMem], stream: cudart.cudaStream_t):\n",
    "    for mem in inputs + outputs:\n",
    "        mem.free()\n",
    "    cuda_call(cudart.cudaStreamDestroy(stream))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "logger = trt.Logger(trt.Logger.WARNING)\n",
    "\n",
    "with open('model.engine', 'rb') as f:\n",
    "    serialized_engine = f.read()\n",
    "\n",
    "runtime = trt.Runtime(logger)\n",
    "\n",
    "engine = runtime.deserialize_cuda_engine(serialized_engine)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "context = engine.create_execution_context()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs, outputs, bindings, stream = allocate_buffers(engine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "img_path = 'moto.jpeg'\n",
    "\n",
    "image_raw = cv2.imread(img_path)\n",
    "image = cv2.resize(np.array(image_raw), (640,640), interpolation = cv2.INTER_LINEAR)\n",
    "image = np.transpose(image, (2,0,1))\n",
    "\n",
    "image = np.expand_dims(image, axis=0)\n",
    "\n",
    "shape_orig = image_raw.size\n",
    "\n",
    "inputs[0].host = image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _do_inference_base(inputs, outputs, stream, execute_async):\n",
    "    # Transfer input data to the GPU.\n",
    "    kind = cudart.cudaMemcpyKind.cudaMemcpyHostToDevice\n",
    "    [cuda_call(cudart.cudaMemcpyAsync(inp.device, inp.host, inp.nbytes, kind, stream)) for inp in inputs]\n",
    "    # Run inference.\n",
    "    execute_async()\n",
    "    # Transfer predictions back from the GPU.\n",
    "    kind = cudart.cudaMemcpyKind.cudaMemcpyDeviceToHost\n",
    "    [cuda_call(cudart.cudaMemcpyAsync(out.host, out.device, out.nbytes, kind, stream)) for out in outputs]\n",
    "    # Synchronize the stream\n",
    "    cuda_call(cudart.cudaStreamSynchronize(stream))\n",
    "    # Return only the host outputs.\n",
    "    return [out.host for out in outputs]\n",
    "\n",
    "def do_inference_v2(context, bindings, inputs, outputs, stream):\n",
    "    def execute_async():\n",
    "        context.execute_async_v2(bindings=bindings, stream_handle=stream)\n",
    "    return _do_inference_base(inputs, outputs, stream, execute_async)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nms(bounding_boxes, confidence_score, threshold):\n",
    "    # If no bounding boxes, return empty list\n",
    "    if len(bounding_boxes) == 0:\n",
    "        return [], []\n",
    "\n",
    "    # Bounding boxes\n",
    "    boxes = np.array(bounding_boxes)\n",
    "\n",
    "    # coordinates of bounding boxes\n",
    "    start_x = boxes[:, 0]\n",
    "    start_y = boxes[:, 1]\n",
    "    end_x = boxes[:, 2]\n",
    "    end_y = boxes[:, 3]\n",
    "\n",
    "    # Confidence scores of bounding boxes\n",
    "    score = np.array(confidence_score)\n",
    "\n",
    "    # Picked bounding boxes\n",
    "    picked_boxes = []\n",
    "    picked_score = []\n",
    "\n",
    "    # Compute areas of bounding boxes\n",
    "    areas = (end_x - start_x + 1) * (end_y - start_y + 1)\n",
    "\n",
    "    # Sort by confidence score of bounding boxes\n",
    "    order = np.argsort(score)\n",
    "\n",
    "    # Iterate bounding boxes\n",
    "    while order.size > 0:\n",
    "        # The index of largest confidence score\n",
    "        index = order[-1]\n",
    "\n",
    "        # Pick the bounding box with largest confidence score\n",
    "        picked_boxes.append(bounding_boxes[index])\n",
    "        picked_score.append(confidence_score[index])\n",
    "\n",
    "        # Compute ordinates of intersection-over-union(IOU)\n",
    "        x1 = np.maximum(start_x[index], start_x[order[:-1]])\n",
    "        x2 = np.minimum(end_x[index], end_x[order[:-1]])\n",
    "        y1 = np.maximum(start_y[index], start_y[order[:-1]])\n",
    "        y2 = np.minimum(end_y[index], end_y[order[:-1]])\n",
    "\n",
    "        # Compute areas of intersection-over-union\n",
    "        w = np.maximum(0.0, x2 - x1 + 1)\n",
    "        h = np.maximum(0.0, y2 - y1 + 1)\n",
    "        intersection = w * h\n",
    "\n",
    "        # Compute the ratio between intersection and union\n",
    "        ratio = intersection / (areas[index] + areas[order[:-1]] - intersection)\n",
    "\n",
    "        left = np.where(ratio < threshold)\n",
    "        order = order[left]\n",
    "\n",
    "    return picked_boxes, picked_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 3, 640, 640)\n",
      "(1, 1000, 4)\n",
      "(1, 1000, 5)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_5813/280389308.py:1: DeprecationWarning: Use get_tensor_shape instead.\n",
      "  print(engine.get_binding_shape(0))\n",
      "/tmp/ipykernel_5813/280389308.py:2: DeprecationWarning: Use get_tensor_shape instead.\n",
      "  print(engine.get_binding_shape(1))\n",
      "/tmp/ipykernel_5813/280389308.py:3: DeprecationWarning: Use get_tensor_shape instead.\n",
      "  print(engine.get_binding_shape(2))\n"
     ]
    }
   ],
   "source": [
    "print(engine.get_binding_shape(0))\n",
    "print(engine.get_binding_shape(1))\n",
    "print(engine.get_binding_shape(2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[18.734022073635362, 22.715133659720117, 19.078112704629085, 21.016495299941877, 20.783532944516846, 20.980121849958483, 20.724996170551293, 19.929221704837023, 19.16931669127023, 21.5251467750544, 22.411935066739336, 20.071609392870645, 20.21926234447385, 19.817450755267025, 19.001621861607184, 20.846855802302233, 20.31228479691609, 20.665464471181796, 19.453378353307855, 19.285575030806864, 19.815484626868493, 20.18306843171505, 20.14806844274501, 20.3860331285481, 20.25607541629641, 19.712020453146224, 20.2967543999729, 19.658526982817612, 20.011660694775113, 20.37444683548608, 19.854975455272736, 20.461416877250155, 19.84727131628882, 20.193854657153036, 19.73994484134828, 19.77932140246634, 19.71072356703463, 20.34203570510551, 19.851028685828414, 17.18927735679714, 19.79995656976689, 19.766644202628765, 19.439583613349956, 20.010992366412214, 20.24385464479292, 19.71581945867687, 19.797993910929645, 19.941539485570296, 19.693787093381413]\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "output_shapes = [(1,1000,4),(1,1000,5)]\n",
    "times=[]\n",
    "for i in range(1,50):\n",
    "    t0=time.time()\n",
    "    trt_outputs = do_inference_v2(context , bindings=bindings, inputs=inputs, outputs=outputs, stream=stream)\n",
    "    t1= time.time()\n",
    "    times.append(1/(t1-t0))\n",
    "    \n",
    "print(times)\n",
    "trt_outputs = [output.reshape(shape) for output, shape in zip(trt_outputs, output_shapes)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "vec = []\n",
    "boxes = []\n",
    "scores = []\n",
    "import torch\n",
    "sf = torch.nn.Softmax(dim=1)\n",
    "for i in range(0,1000):\n",
    "    xc,yc,w,h = trt_outputs[0][0,i,:]\n",
    "    \n",
    "    out = list(trt_outputs[1][0,i,:] )\n",
    "    \n",
    "    boxes.append( (xc,yc,w,h) )\n",
    "    scores.append(max(out))\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "23"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "boxes_nms, scores_nms = nms(boxes, scores,0.05)\n",
    "len(boxes_nms)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Provo con yolo nas non quantizzato, converto e vedo le differenze nelle dimensioni.... vorrei capire dove sono le classi... ora ho soltanto 4 sembra!!!! dovrebbero essere 5\n",
    "\n",
    "-- yolo_nas_s(standard) : (1,1000,4)(1,1000,80)\n",
    "-- (retrain quantized)  : (1,8400,4)(1,8400,5) (invertiti non so perchÃ¨)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import ImageDraw\n",
    "from PIL import Image\n",
    "image = Image.open(img_path)\n",
    "image = image.resize((640,640))\n",
    "draw = ImageDraw.Draw(image)\n",
    "for box in boxes_nms:\n",
    "        x1,y1,x2,y2 = box[0],box[1],box[2],box[3]\n",
    "        #print(f'{x1}_{y1}_{x2}_{y2}')\n",
    "        bbox = [(x1,y1),(x2,y2)]\n",
    "        draw.rectangle(bbox, outline=\"black\")\n",
    "        \n",
    "image.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "free_buffers(inputs, outputs, stream)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
  },
  "kernelspec": {
   "display_name": "Python 3.10.12 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
